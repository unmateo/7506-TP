{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "this = os.getcwd()\n",
    "path = this[:this.rfind(\"/\")]\n",
    "if not path in sys.path: sys.path.append(path)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from datos import FEATURES_DISPONIBLES\n",
    "from modelo import Modelo\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from operator import concat\n",
    "from functools import reduce\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostRegressor(Modelo):\n",
    "    \"\"\"\n",
    "        Este modelo lo vamos a usar para predecir algunos\n",
    "        valores faltantes en los tres sets de datos.\n",
    "    \"\"\"\n",
    "\n",
    "     \n",
    "    def cargar_datos(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        excluir = {\n",
    "            \"idzona\",\n",
    "            \"precio_metro_cubierto\",\n",
    "            \"precio_metro_total\",\n",
    "            \"gps\", \"lat\", \"lng\"\n",
    "        }\n",
    "        features = FEATURES_DISPONIBLES - excluir\n",
    "        super().cargar_datos(features)\n",
    "        self.train_data = self.preparar_datos(self.train_data)\n",
    "        self.test_data = self.preparar_datos(self.test_data)      \n",
    "        self.submit_data = self.preparar_datos(self.submit_data)\n",
    "        self.agregar_columnas_faltantes()\n",
    "        return True\n",
    "    \n",
    "    def preparar_datos(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        df = df.drop(columns=[\"fecha\", \"titulo\", \"descripcion\"]) \n",
    "        categoricas = {\"tipodepropiedad\", \"provincia\", \"ciudad\"}\n",
    "        return self.one_hot_encode(df, categoricas)\n",
    "    \n",
    "    def agregar_columnas_faltantes(self):\n",
    "        \"\"\"\n",
    "            Al hacer one hot encoding individualemente sobre los dfs,\n",
    "            puede pasar que queden con columnas dispares. Por eso,\n",
    "            en esta función las agrego a cada uno.\n",
    "        \"\"\"\n",
    "        dfs = (self.train_data, self.test_data, self.submit_data)\n",
    "        columnas_todas = set(reduce(concat, [list(df.columns.values) for df in dfs], []))\n",
    "        def agregar_faltantes(df):\n",
    "            faltantes = list(columnas_todas - {'precio'} - set(df.columns.values))\n",
    "            for faltante in faltantes:\n",
    "                df[faltante] = False\n",
    "            return df.reindex(columnas_todas, axis='columns')\n",
    "        self.train_data = agregar_faltantes(self.train_data)\n",
    "        self.test_data = agregar_faltantes(self.test_data)\n",
    "        self.submit_data = agregar_faltantes(self.submit_data)\n",
    "        return True\n",
    "\n",
    "    def _split_data_label(self, df, label):\n",
    "        data = df.loc[:, df.columns != label]\n",
    "        label = df[label].values if label in df.columns else None\n",
    "        return data, label\n",
    "    \n",
    "    @Modelo.cronometrar()\n",
    "    def entrenar(self, params=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        hiperparametros = {\n",
    "            'learning_rate': 0.1,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'mae',\n",
    "            'max_depth': 10,\n",
    "            'number_estimators': 500,\n",
    "            'gamma': 0.5,\n",
    "            'min_child_weight': 5,\n",
    "            'reg_alpha': 0.5,\n",
    "            'reg_lambda': 1,\n",
    "            'base_score': 500000\n",
    "        }\n",
    "        if params:\n",
    "            hiperparametros.update(params)\n",
    "        train_data, train_label = self._split_data_label(self.train_data, self.feature)\n",
    "        self.model = xgb.XGBRegressor(**hiperparametros)\n",
    "        self.model.fit(train_data, train_label)\n",
    "        super().entrenar()\n",
    "        return True\n",
    "    \n",
    "    @Modelo.cronometrar()\n",
    "    def predecir(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        data = df.copy()\n",
    "        predict_data, predict_label = self._split_data_label(data, self.feature)\n",
    "        predictions = self.model.predict(predict_data)\n",
    "        data[\"target\"] = predictions\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_tuple(params):\n",
    "    return tuple(params.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probar_parametros(modelo, params):\n",
    "    modelo.entrenar(params)\n",
    "    return modelo.validar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_prueba(parametros):\n",
    "    prueba = parametros.copy()\n",
    "    return {key:choice(values) for key,values in prueba.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_n_pruebas(n, parametros):\n",
    "    pruebas = []\n",
    "    set_pruebas = set()\n",
    "    while len(pruebas) < n:\n",
    "        prueba = random_prueba(parametros)\n",
    "        prueba_tuple = params_to_tuple(prueba)\n",
    "        if prueba_tuple in set_pruebas: continue\n",
    "        pruebas.append(prueba)\n",
    "        set_pruebas.add(prueba_tuple)\n",
    "    return pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_hiperparametros():\n",
    "    resultados = {}\n",
    "    modelo = XGBoostRegressor()\n",
    "    modelo.cargar_datos()\n",
    "    cantidad_pruebas = 10\n",
    "    opciones = {\n",
    "        'learning_rate': [0.1, 0.01],\n",
    "        'max_depth': [10, 15, 20, 25],\n",
    "        'number_estimators': [500, 750, 1000, 1500],\n",
    "        'gamma': [0, 0.5, 1, 2, 4],\n",
    "        'min_child_weight': [5, 7, 10],\n",
    "        'reg_alpha': [0, 0.5, 1],\n",
    "        'reg_lambda': [0, 0.5, 1],\n",
    "        'base_score': [200000, 500000, 1000000, 2000000]\n",
    "    }\n",
    "    pruebas = generar_n_pruebas(cantidad_pruebas, opciones)\n",
    "    for prueba in pruebas:\n",
    "        print(prueba)\n",
    "        puntaje = probar_parametros(modelo, prueba)\n",
    "        print(puntaje)\n",
    "        resultados[params_to_tuple(prueba)] = puntaje\n",
    "        print(resultados)\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejores hiperparámetros\n",
    "{'learning_rate': 0.1, 'max_depth': 15, 'number_estimators': 500, 'gamma': 0.5, 'min_child_weight': 5, 'reg_alpha': 0.5, 'reg_lambda': 1, 'base_score': 500000}\n",
    "\n",
    "{'learning_rate': 0.1, 'max_depth': 15, 'number_estimators': 500, 'gamma': 1, 'min_child_weight': 7, 'reg_alpha': 1, 'reg_lambda': 1, 'base_score': 2000000}\n",
    "\n",
    "{'learning_rate': 0.1, 'max_depth': 15, 'number_estimators': 1000, 'gamma': 2, 'min_child_weight': 7, 'reg_alpha': 0.5, 'reg_lambda': 0.5, 'base_score': 1000000}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
